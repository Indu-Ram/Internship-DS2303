{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa0ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (2.27.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ffi (c:\\users\\user\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91021158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9985747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page= requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7792e951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 : Main Page\n",
      "h1 : Welcome to Wikipedia\n",
      "h2 : From today's featured article\n",
      "h2 : Did you know ...\n",
      "h2 : In the news\n",
      "h2 : On this day\n",
      "h2 : Today's featured picture\n",
      "h2 : Other areas of Wikipedia\n",
      "h2 : Wikipedia's sister projects\n",
      "h2 : Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "header_tags=['h1','h2','h3','h4','h5','h6','h7']\n",
    "for i in soup.find_all(header_tags):    \n",
    "    print(i.name + ' : ' + i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b82939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Write a python program to display IMDB’s Top rated 100 movies’ data(i.e.Name, IMDB rating, Year of release)and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56fc6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Response [200]>, <Response [200]>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iMDb = requests.get(\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\")\n",
    "iMDb1 = requests.get(\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt\")\n",
    "iMDb1, iMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a93387",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(iMDb.content,'html.parser')\n",
    "soup2 = BeautifulSoup(iMDb1.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783837b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Movie1 = soup1.find_all(['h3'], class_ = \"lister-item-header\")\n",
    "Movie_name = []\n",
    "\n",
    "for i in Movie1:\n",
    "    Movie_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "Movie2 = soup2.find_all(['h3'], class_ = \"lister-item-header\")\n",
    "for i in Movie2:\n",
    "    Movie_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "Movie_name = [i.split('.')[1] for i in Movie_name]\n",
    "Movie_name = [i.split('(')[0] for i in Movie_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f0f5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rate1 = soup1.find_all(['div'], class_ = \"inline-block ratings-imdb-rating\")\n",
    "Rate2 = soup2.find_all(['div'], class_ = \"inline-block ratings-imdb-rating\")\n",
    "ratings = []\n",
    "\n",
    "for i in Rate1:\n",
    "    ratings.append(i.get_text().replace('\\n',''))\n",
    "for i in Rate2:\n",
    "    ratings.append(i.get_text().replace('\\n',''))    \n",
    "    \n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1841ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = soup1.find_all(['span'], class_ = \"lister-item-year text-muted unbold\")\n",
    "y2 = soup2.find_all(['span'], class_ = \"lister-item-year text-muted unbold\")\n",
    "\n",
    "year = []\n",
    "\n",
    "for i in y1:\n",
    "    year.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in y2:\n",
    "    year.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "year = [i.split('(')[-1] for i in year] \n",
    "year = [i.split(')')[0] for i in year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d709d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_movies= {\"Name\":Movie_name, \"IMDB_rating\": ratings, \"Year\":year }\n",
    "import pandas as pd\n",
    "IMDB_top_100_movies = pd.DataFrame(top_100_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a392aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB_rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Apartment</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ikiru</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name IMDB_rating  Year\n",
       "0            The Shawshank Redemption         9.3  1994\n",
       "1                       The Godfather         9.2  1972\n",
       "2                     The Dark Knight         9.0  2008\n",
       "3                    Schindler's List         9.0  1993\n",
       "4                        12 Angry Men         9.0  1957\n",
       "..                                ...         ...   ...\n",
       "95                 North by Northwest         8.3  1959\n",
       "96                Singin' in the Rain         8.3  1952\n",
       "97  M - Eine Stadt sucht einen Mörder         8.3  1931\n",
       "98                      The Apartment         8.3  1960\n",
       "99                              Ikiru         8.3  1952\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_top_100_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Write a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of \n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef68011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_movies = requests.get(\"https://www.imdb.com/list/ls056092300/\")\n",
    "indian_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95e8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = BeautifulSoup(indian_movies.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d3c847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_movie = sp.find_all(['h3'], class_ = \"lister-item-header\")\n",
    "ind_movie_fullname = []\n",
    "\n",
    "for i in ind_movie:\n",
    "    ind_movie_fullname.append(i.text.replace(\"\\n\",\"\"))\n",
    "  \n",
    "ind_movie_fullname = [i.split('.',1)[1] for i in ind_movie_fullname]\n",
    "ind_movie_name = [i.split('(')[0] for i in ind_movie_fullname]\n",
    "Year = [i.split('(')[-1] for i in ind_movie_fullname]\n",
    "Year = [i.split(')')[0] for i in Year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e7157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = sp.find_all(['div'], class_ = \"ipl-rating-star small\")\n",
    "ratings = []\n",
    "\n",
    "for i in rate:\n",
    "    ratings.append(i.get_text().replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f150d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>IMDB_rating</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ship of Theseus</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iruvar</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaagaz Ke Phool</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kanchivaram</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Monsoon Wedding</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Black</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Deewaar</td>\n",
       "      <td>8</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name IMDB_rating  Year\n",
       "0                     Ship of Theseus           8  2012\n",
       "1                              Iruvar         8.4  1997\n",
       "2                     Kaagaz Ke Phool         7.8  1959\n",
       "3   Lagaan: Once Upon a Time in India         8.1  2001\n",
       "4                     Pather Panchali         8.2  1955\n",
       "..                                ...         ...   ...\n",
       "95                        Apur Sansar         8.5  1959\n",
       "96                        Kanchivaram         8.1  2008\n",
       "97                    Monsoon Wedding         7.3  2001\n",
       "98                              Black         8.1  2005\n",
       "99                            Deewaar           8  1975\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_rated_100_Indianmovies=pd.DataFrame({\"Name\":ind_movie_name, \"IMDB_rating\": ratings, \"Year\":Year })\n",
    "Top_rated_100_Indianmovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9dbf1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_rated_100_Indianmovies.to_csv(\"Top_rated_100_Indianmovies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9271eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb47847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "\t\t\t Former Presidents List\n",
      "--------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of President (life span)</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name of President (life span)  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13              Dr. Rajendra Prasad (1884-1963)   \n",
       "\n",
       "                                       Term of Office  \n",
       "0                      25 July, 2017 to 25 July, 2022  \n",
       "1                      25 July, 2012 to 25 July, 2017  \n",
       "2                      25 July, 2007 to 25 July, 2012  \n",
       "3                      25 July, 2002 to 25 July, 2007  \n",
       "4                      25 July, 1997 to 25 July, 2002  \n",
       "5                      25 July, 1992 to 25 July, 1997  \n",
       "6                      25 July, 1987 to 25 July, 1992  \n",
       "7                      25 July, 1982 to 25 July, 1987  \n",
       "8                      25 July, 1977 to 25 July, 1982  \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page3= requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup3= BeautifulSoup(page3.content)\n",
    "\n",
    "President_name=[]\n",
    "for i in soup3.find_all('div', class_=\"presidentListing\"):\n",
    "    cells = i.find_all('h3')\n",
    "    President_name.append(cells[0].text.strip())\n",
    "\n",
    "Term=[]\n",
    "for i in soup3.find_all('div', class_=\"presidentListing\"):\n",
    "    cells = i.find_all('p')\n",
    "    Term.append(cells[0].text.strip().replace('Term of Office:',''))\n",
    "\n",
    "print('-'*68)\n",
    "print('\\t\\t\\t Former Presidents List')\n",
    "print('-'*68)\n",
    "\n",
    "df_president=pd.DataFrame({'Name of President (life span)':President_name,'Term of Office':Term})\n",
    "df_president"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018aaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\u0002a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca3834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\t Top 10 ODI Teams in Men's Cricket\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia , AUS</td>\n",
       "      <td>23</td>\n",
       "      <td>2,714</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pakistan , PAK</td>\n",
       "      <td>20</td>\n",
       "      <td>2,316</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>India , IND</td>\n",
       "      <td>33</td>\n",
       "      <td>3,807</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>New Zealand , NZ</td>\n",
       "      <td>27</td>\n",
       "      <td>2,806</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>England , ENG</td>\n",
       "      <td>24</td>\n",
       "      <td>2,426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Africa , SA</td>\n",
       "      <td>19</td>\n",
       "      <td>1,910</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh , BAN</td>\n",
       "      <td>25</td>\n",
       "      <td>2,451</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Afghanistan , AFG</td>\n",
       "      <td>10</td>\n",
       "      <td>878</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka , SL</td>\n",
       "      <td>21</td>\n",
       "      <td>1,682</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>West Indies , WI</td>\n",
       "      <td>25</td>\n",
       "      <td>1,797</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranking               Team Matches Points Rating\n",
       "0       1    Australia , AUS      23  2,714    118\n",
       "1       2     Pakistan , PAK      20  2,316    116\n",
       "2       3        India , IND      33  3,807    115\n",
       "3       4   New Zealand , NZ      27  2,806    104\n",
       "4       5      England , ENG      24  2,426    101\n",
       "5       6  South Africa , SA      19  1,910    101\n",
       "6       7   Bangladesh , BAN      25  2,451     98\n",
       "7       8  Afghanistan , AFG      10    878     88\n",
       "8       9     Sri Lanka , SL      21  1,682     80\n",
       "9      10   West Indies , WI      25  1,797     72"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4= requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup4= BeautifulSoup(page4.content)\n",
    "\n",
    "Team=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "Ranking=[]\n",
    "for i in soup4.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Ranking.append(cells[0].text.strip())\n",
    "        Team.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Matches.append(cells[2].text.strip())\n",
    "        Points.append(cells[3].text.strip())\n",
    "        Rating.append(cells[4].text.strip())\n",
    "        \n",
    "print('-'*50)\n",
    "print(\"\\t Top 10 ODI Teams in Men's Cricket\")\n",
    "print('-'*50)\n",
    "\n",
    "df_team = pd.DataFrame({'Ranking':Ranking,'Team':Team,'Matches':Matches,'Points':Points,'Rating':Rating})  \n",
    "df_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ee5264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      " Top 10 ODI Batsmen in Men's Cricket\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team Rating\n",
       "0             Babar Azam  PAK    886\n",
       "1  Rassie van der Dussen   SA    777\n",
       "2           Fakhar Zaman  PAK    755\n",
       "3            Imam-ul-Haq  PAK    745\n",
       "4           Shubman Gill  IND    738\n",
       "5           David Warner  AUS    726\n",
       "6           Harry Tector  IRE    722\n",
       "7            Virat Kohli  IND    719\n",
       "8        Quinton de Kock   SA    718\n",
       "9           Rohit Sharma  IND    707"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4_b= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup4_b= BeautifulSoup(page4_b.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup4_b.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "        \n",
    "print('-'*40)\n",
    "print(\" Top 10 ODI Batsmen in Men's Cricket\")\n",
    "print('-'*40)\n",
    "\n",
    "df_batting= pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})  \n",
    "df_batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c) Top 10 ODI bowlers along with the records of their team andrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570e3fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> \n",
      "\n",
      "----------------------------------------\n",
      "  Top 10 ODI Bowlers in Men's Cricket\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0    Josh Hazlewood  AUS    705\n",
       "1    Mohammed Siraj  IND    691\n",
       "2    Mitchell Starc  AUS    686\n",
       "3        Matt Henry   NZ    667\n",
       "4       Trent Boult   NZ    660\n",
       "5       Rashid Khan  AFG    659\n",
       "6        Adam Zampa  AUS    652\n",
       "7  Mujeeb Ur Rahman  AFG    637\n",
       "8     Mohammad Nabi  AFG    631\n",
       "9    Shaheen Afridi  PAK    630"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4_c= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "print(page4,'\\n')\n",
    "soup4_c= BeautifulSoup(page4_c.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup4_c.find_all ('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "\n",
    "print('-'*40)\n",
    "print(\"  Top 10 ODI Bowlers in Men's Cricket\")\n",
    "print('-'*40)\n",
    "\n",
    "df_bowling=pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})\n",
    "df_bowling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\u0002a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ef267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "     Top 10 ODI Teams in Women's Cricket\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia , AUS</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England , ENG</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa , SA</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India , IND</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand , NZ</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies , WI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Thailand , THA</td>\n",
       "      <td>11</td>\n",
       "      <td>821</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Bangladesh , BAN</td>\n",
       "      <td>14</td>\n",
       "      <td>977</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Pakistan , PAK</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka , SL</td>\n",
       "      <td>9</td>\n",
       "      <td>479</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking               Team Matches Points Rating\n",
       "0        1    Australia , AUS      21  3,603    172\n",
       "1        2      England , ENG      28  3,342    119\n",
       "2        3  South Africa , SA      26  3,098    119\n",
       "3        4        India , IND      27  2,820    104\n",
       "4        5   New Zealand , NZ      25  2,553    102\n",
       "5        6   West Indies , WI      27  2,535     94\n",
       "6        7     Thailand , THA      11    821     75\n",
       "7        8   Bangladesh , BAN      14    977     70\n",
       "8        9     Pakistan , PAK      27  1,678     62\n",
       "9       10     Sri Lanka , SL       9    479     53"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5= requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup5= BeautifulSoup(page5.content)\n",
    "\n",
    "Team=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "Ranking=[]\n",
    "for i in soup5.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Ranking.append(cells[0].text.strip())\n",
    "        Team.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Matches.append(cells[2].text.strip())\n",
    "        Points.append(cells[3].text.strip())\n",
    "        Rating.append(cells[4].text.strip())\n",
    "\n",
    "print('-'*45)\n",
    "print(\"     Top 10 ODI Teams in Women's Cricket\")\n",
    "print('-'*45)\n",
    "\n",
    "df_team1 = pd.DataFrame({' Ranking':Ranking,'Team':Team,'Matches':Matches,'Points':Points,'Rating':Rating})  \n",
    "df_team1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a70367",
   "metadata": {},
   "outputs": [],
   "source": [
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a1f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "  Top 10 ODI Batting Players in Women's Cricket\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Rating\n",
       "0          Beth Mooney  AUS    754\n",
       "1      Laura Wolvaardt   SA    732\n",
       "2       Natalie Sciver  ENG    731\n",
       "3          Meg Lanning  AUS    717\n",
       "4     Harmanpreet Kaur  IND    716\n",
       "5      Smriti Mandhana  IND    714\n",
       "6  Chamari Athapaththu   SL    673\n",
       "7         Ellyse Perry  AUS    626\n",
       "8       Tammy Beaumont  ENG    595\n",
       "9      Stafanie Taylor   WI    588"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5_b= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup5_b= BeautifulSoup(page5_b.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup5_b.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "        \n",
    "print('-'*50)\n",
    "print(\"  Top 10 ODI Batting Players in Women's Cricket\")\n",
    "print('-'*50)\n",
    "\n",
    "df_batting1= pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})  \n",
    "df_batting1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6b1794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Top 10 women’s ODI all-rounder in Women's Cricket\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0    Hayley Matthews   WI    373\n",
       "1     Natalie Sciver  ENG    371\n",
       "2       Ellyse Perry  AUS    366\n",
       "3     Marizanne Kapp   SA    349\n",
       "4        Amelia Kerr   NZ    336\n",
       "5      Deepti Sharma  IND    322\n",
       "6   Ashleigh Gardner  AUS    292\n",
       "7      Jess Jonassen  AUS    250\n",
       "8           Nida Dar  PAK    232\n",
       "9  Sophie Ecclestone  ENG    205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5_c= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup5_c= BeautifulSoup(page5_c.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup5_c.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "        \n",
    "print('-'*50)\n",
    "print(\"Top 10 women’s ODI all-rounder in Women's Cricket\")\n",
    "print('-'*50)\n",
    "\n",
    "\n",
    "df_All_Rounder= pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})  \n",
    "df_All_Rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and \n",
    "make data frame\u0002i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fd30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "\t\t\t\t\t News Details\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNBC Daily Open: After the debt ceiling, infla...</td>\n",
       "      <td>23 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/stock-markets-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Europe markets head for higher open after U.S....</td>\n",
       "      <td>44 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chinese consumers won't return to pre-Covid sp...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/morgan-stanley...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The biggest money mistakes that could change y...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/the-money-mist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey's lira sinks to near record low as Erdo...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/turkeys-lira-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Major central banks were expected to pause rat...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/major-central-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNBC Daily Open: First the debt ceiling, then ...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/stock-markets-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TSMC or Samsung? One chipmaker is the better p...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/tsmc-or-samsun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How much of A.I. is just hype? A bull and a be...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/is-ai-here-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asia markets mixed after U.S. reaches debt cei...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/29/asia-markets.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkey's President Erdogan seals election vict...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/turkeys-presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Debt ceiling deal will be 'transformational' f...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/debt-ceiling-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NYC, Las Vegas, D.C.: Free wellness activities...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/nyc-las-vegas-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Content creators bring in up to $150/hour film...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/content-creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34-year-old makes up to $167 an hour nannying ...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/gloria-richard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This winning fund puts a spin on emerging mark...</td>\n",
       "      <td>18 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/this-winning-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ASCO will put the focus on the cancer fight. T...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/asco-will-focu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Now Boarding: Why airlines are turning to bigg...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/now-boarding-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Global demand for streaming Asian movies, TV g...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/squid-game-eea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>These are the cheapest tech stocks in the S&amp;P 500</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/these-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Turkey votes in runoff election after candidat...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/turkey-electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>White House and Republicans reach a tentative ...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/white-house-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>State Farm to stop accepting homeowners insura...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/state-farm-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How Janie Deegan built Janie's Life-Changing B...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-janie-deeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Top 10 cheapest places in the U.S. to buy a be...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/cheapest-place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mark Cuban calls Elon Musk’s Twitter algorithm...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/mark-cuban-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3 investing tips as the federal debt ceiling '...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-to-invest-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Microsoft keyboard users are ‘devastated’ afte...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/microsoft-keyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Steve Adcock: The 3 'stupidest' myths I've hea...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/steve-adcock-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Chip stocks AMD and Nvidia are among the most ...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/chip-stocks-am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          Time  \\\n",
       "0   CNBC Daily Open: After the debt ceiling, infla...    23 Min Ago   \n",
       "1   Europe markets head for higher open after U.S....    44 Min Ago   \n",
       "2   Chinese consumers won't return to pre-Covid sp...   2 Hours Ago   \n",
       "3   The biggest money mistakes that could change y...   3 Hours Ago   \n",
       "4   Turkey's lira sinks to near record low as Erdo...   3 Hours Ago   \n",
       "5   Major central banks were expected to pause rat...   4 Hours Ago   \n",
       "6   CNBC Daily Open: First the debt ceiling, then ...   6 Hours Ago   \n",
       "7   TSMC or Samsung? One chipmaker is the better p...   7 Hours Ago   \n",
       "8   How much of A.I. is just hype? A bull and a be...   7 Hours Ago   \n",
       "9   Asia markets mixed after U.S. reaches debt cei...   7 Hours Ago   \n",
       "10  Turkey's President Erdogan seals election vict...  13 Hours Ago   \n",
       "11  Debt ceiling deal will be 'transformational' f...  15 Hours Ago   \n",
       "12  NYC, Las Vegas, D.C.: Free wellness activities...  17 Hours Ago   \n",
       "13  Content creators bring in up to $150/hour film...  17 Hours Ago   \n",
       "14  34-year-old makes up to $167 an hour nannying ...  18 Hours Ago   \n",
       "15  This winning fund puts a spin on emerging mark...  18 Hours Ago   \n",
       "16  ASCO will put the focus on the cancer fight. T...  19 Hours Ago   \n",
       "17  Now Boarding: Why airlines are turning to bigg...  19 Hours Ago   \n",
       "18  Global demand for streaming Asian movies, TV g...  19 Hours Ago   \n",
       "19  These are the cheapest tech stocks in the S&P 500  19 Hours Ago   \n",
       "20  Turkey votes in runoff election after candidat...  May 27, 2023   \n",
       "21  White House and Republicans reach a tentative ...  May 27, 2023   \n",
       "22  State Farm to stop accepting homeowners insura...  May 27, 2023   \n",
       "23  How Janie Deegan built Janie's Life-Changing B...  May 27, 2023   \n",
       "24  Top 10 cheapest places in the U.S. to buy a be...  May 27, 2023   \n",
       "25  Mark Cuban calls Elon Musk’s Twitter algorithm...  May 27, 2023   \n",
       "26  3 investing tips as the federal debt ceiling '...  May 27, 2023   \n",
       "27  Microsoft keyboard users are ‘devastated’ afte...  May 27, 2023   \n",
       "28  Steve Adcock: The 3 'stupidest' myths I've hea...  May 27, 2023   \n",
       "29  Chip stocks AMD and Nvidia are among the most ...  May 27, 2023   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2023/05/29/stock-markets-...  \n",
       "1   https://www.cnbc.com/2023/05/29/european-marke...  \n",
       "2   https://www.cnbc.com/2023/05/29/morgan-stanley...  \n",
       "3   https://www.cnbc.com/2023/05/29/the-money-mist...  \n",
       "4   https://www.cnbc.com/2023/05/29/turkeys-lira-s...  \n",
       "5   https://www.cnbc.com/2023/05/29/major-central-...  \n",
       "6   https://www.cnbc.com/2023/05/29/stock-markets-...  \n",
       "7   https://www.cnbc.com/2023/05/29/tsmc-or-samsun...  \n",
       "8   https://www.cnbc.com/2023/05/29/is-ai-here-to-...  \n",
       "9   https://www.cnbc.com/2023/05/29/asia-markets.html  \n",
       "10  https://www.cnbc.com/2023/05/28/turkeys-presid...  \n",
       "11  https://www.cnbc.com/2023/05/28/debt-ceiling-d...  \n",
       "12  https://www.cnbc.com/2023/05/28/nyc-las-vegas-...  \n",
       "13  https://www.cnbc.com/2023/05/28/content-creato...  \n",
       "14  https://www.cnbc.com/2023/05/28/gloria-richard...  \n",
       "15  https://www.cnbc.com/2023/05/28/this-winning-f...  \n",
       "16  https://www.cnbc.com/2023/05/28/asco-will-focu...  \n",
       "17  https://www.cnbc.com/2023/05/28/now-boarding-a...  \n",
       "18  https://www.cnbc.com/2023/05/28/squid-game-eea...  \n",
       "19  https://www.cnbc.com/2023/05/28/these-are-the-...  \n",
       "20  https://www.cnbc.com/2023/05/28/turkey-electio...  \n",
       "21  https://www.cnbc.com/2023/05/27/white-house-an...  \n",
       "22  https://www.cnbc.com/2023/05/27/state-farm-to-...  \n",
       "23  https://www.cnbc.com/2023/05/27/how-janie-deeg...  \n",
       "24  https://www.cnbc.com/2023/05/27/cheapest-place...  \n",
       "25  https://www.cnbc.com/2023/05/27/mark-cuban-say...  \n",
       "26  https://www.cnbc.com/2023/05/27/how-to-invest-...  \n",
       "27  https://www.cnbc.com/2023/05/27/microsoft-keyb...  \n",
       "28  https://www.cnbc.com/2023/05/27/steve-adcock-t...  \n",
       "29  https://www.cnbc.com/2023/05/27/chip-stocks-am...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page7= requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup7= BeautifulSoup(page7.content)\n",
    "\n",
    "headline=[]\n",
    "for i in soup7.find_all('a', class_=\"LatestNews-headline\"):\n",
    "    headline.append(i.get('title'))\n",
    "\n",
    "time=[]\n",
    "for i in soup7.find_all('span', class_=\"LatestNews-wrapper\"):\n",
    "    time.append(i.text)\n",
    "\n",
    "News_Link = []\n",
    "for i in soup7.findAll('a',class_=\"LatestNews-headline\"):\n",
    "    News_Link.append(i.get('href'))\n",
    "\n",
    "print('-'*90)\n",
    "print('\\t\\t\\t\\t\\t News Details')\n",
    "print('-'*90)\n",
    "\n",
    "News=pd.DataFrame({'Headline': headline, 'Time': time,'News Link': News_Link})\n",
    "News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd75589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame\u0002i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ad19f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "\t\t\t\t\t\t Most Downloaded Articles\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Paper Title, Authors, Published Date, Paper URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page8= requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup8= BeautifulSoup(page8.content)\n",
    "\n",
    "Paper_Title=[]\n",
    "for i in soup8.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    Paper_Title.append(i.text)\n",
    "\n",
    "Authors=[]\n",
    "for i in soup8.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    Authors.append(i.text)  \n",
    "\n",
    "Published_Date=[]\n",
    "for i in soup8.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    Published_Date.append(i.text)  \n",
    "\n",
    "Paper_URL=[]\n",
    "for i in soup8.find_all('a', class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    Paper_URL.append(i.get('href'))\n",
    "\n",
    "print('-'*127)\n",
    "print('\\t\\t\\t\\t\\t\\t Most Downloaded Articles')\n",
    "print('-'*127)\n",
    "\n",
    "Articles=pd.DataFrame({'Paper Title': Paper_Title,'Authors': Authors,'Published Date': Published_Date, 'Paper URL':Paper_URL})\n",
    "Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.Write a python program to scrape mentioned details from dineout.co.in and make data frame\u0002i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbb233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "\t\t\t\t\t\t Restaurant Details\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle's Barbeque</td>\n",
       "      <td>Chinese, North</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant_Name               Cuisine  \\\n",
       "0                   Castle Barbeque        Chinese, North   \n",
       "1                   Jungle Jamboree         North Indian,   \n",
       "2                        Cafe Knosh  Italian, Continental   \n",
       "3                 Castle's Barbeque        Chinese, North   \n",
       "4              The Barbeque Company         North Indian,   \n",
       "5                       India Grill         North Indian,   \n",
       "6                    Delhi Barbeque          North Indian   \n",
       "7  The Monarch - Bar Be Que Village          North Indian   \n",
       "8                 Indian Grill Room         North Indian,   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi       4   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "4                 Gardens Galleria,Sector 38A, Noida     3.9   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image_URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page9= requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup9= BeautifulSoup(page9.content)\n",
    "\n",
    "restaurant_name= []\n",
    "for i in soup9.find_all('a', class_=\"restnt-name ellipsis\"):\n",
    "    restaurant_name.append(i.text)\n",
    "\n",
    "Cuisine=[]\n",
    "for i in soup9.find_all('div', class_=\"detail-info\"):\n",
    "    Cuisine.append((i.text.split()[6])+(' ')+(i.text.split()[7]))\n",
    "\n",
    "location=[]\n",
    "for i in soup9.find_all('div', class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "Ratings= []\n",
    "for i in soup9.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "Image_URL= []\n",
    "for i in soup9.find_all('img', class_=\"no-img\"):\n",
    "    Image_URL.append(i['data-src'])\n",
    "\n",
    "print('-'*125)\n",
    "print('\\t\\t\\t\\t\\t\\t Restaurant Details')\n",
    "print('-'*125)\n",
    "\n",
    "dineout=pd.DataFrame({'Restaurant_Name':restaurant_name,'Cuisine':Cuisine,'Location':location,'Ratings':Ratings,'Image_URL':Image_URL})\n",
    "dineout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791f6af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
